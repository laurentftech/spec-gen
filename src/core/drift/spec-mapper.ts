/**
 * Spec-to-File Mapper
 *
 * Reads existing OpenSpec specs and builds a bidirectional mapping
 * between spec domains and source files. This is the core data structure
 * that enables drift detection.
 */

import { readFile, readdir } from 'node:fs/promises';
import { join, relative } from 'node:path';
import type { SpecMapping, SpecMap } from '../../types/index.js';
import logger from '../../utils/logger.js';

// ============================================================================
// TYPES
// ============================================================================

export interface SpecMapperOptions {
  rootPath: string;
  openspecPath: string;
  repoStructurePath?: string;
}

interface RepoStructureDomain {
  name: string;
  files?: string[];
  suggestedSpecPath?: string;
}

// ============================================================================
// SPEC PARSING
// ============================================================================

/**
 * Extract source files from the spec header line:
 *   > Source files: src/foo.ts, src/bar.ts
 */
export function parseSpecHeader(content: string): { sourceFiles: string[]; generatedDate: string | null } {
  const lines = content.split('\n');
  const sourceFiles: string[] = [];
  let generatedDate: string | null = null;

  for (const line of lines) {
    // Match "> Source files: ..." line
    const sourceMatch = line.match(/^>\s*Source files?:\s*(.+)/i);
    if (sourceMatch) {
      const files = sourceMatch[1]
        .split(',')
        .map(f => f.trim().replace(/`/g, ''))
        .filter(Boolean);
      sourceFiles.push(...files);
    }

    // Match "> Generated by spec-gen ... on YYYY-MM-DD"
    const dateMatch = line.match(/^>\s*Generated.*on\s+(\d{4}-\d{2}-\d{2})/i);
    if (dateMatch) {
      generatedDate = dateMatch[1];
    }
  }

  return { sourceFiles, generatedDate };
}

/**
 * Extract file references, requirements, and entities from spec body
 */
export function parseSpecReferences(content: string): {
  files: string[];
  requirements: string[];
  entities: string[];
} {
  const files: string[] = [];
  const requirements: string[] = [];
  const entities: string[] = [];

  // Extract files from Technical Notes: **Implementation**: `file1`, `file2`
  // Also handles multi-line formats where backtick-wrapped files continue on subsequent lines
  const lines = content.split('\n');
  let inImplBlock = false;
  for (const line of lines) {
    if (/\*\*Implementation\*\*:/.test(line)) {
      inImplBlock = true;
      // Extract backtick refs from this line
      const fileRefs = line.match(/`([^`]+)`/g);
      if (fileRefs) {
        files.push(...fileRefs.filter(f => f !== '**Implementation**').map(f => f.replace(/`/g, '').trim()));
      }
    } else if (inImplBlock) {
      // Continue capturing backtick refs from continuation lines (indented, list items, etc.)
      if (line.match(/^\s*[-*]?\s*`[^`]+`/) || line.match(/^\s+`[^`]+`/)) {
        const fileRefs = line.match(/`([^`]+)`/g);
        if (fileRefs) {
          files.push(...fileRefs.map(f => f.replace(/`/g, '').trim()));
        }
      } else {
        // Non-continuation line — stop scanning this Implementation block
        inImplBlock = false;
      }
    }
  }

  // Extract requirement names: ### Requirement: Name
  const reqMatches = content.matchAll(/^###\s+Requirement:\s*(.+)/gm);
  for (const match of reqMatches) {
    requirements.push(match[1].trim());
  }

  // Extract entity names from ## Entities section
  // Look for ### headings that follow ## Entities
  const entitySection = content.match(/## Entities\s*\n([\s\S]*?)(?=\n## |\n$)/);
  if (entitySection) {
    const entityMatches = entitySection[1].matchAll(/^###\s+(\w+)/gm);
    for (const match of entityMatches) {
      entities.push(match[1].trim());
    }
  }

  return { files, requirements, entities };
}

/**
 * Try to infer a domain for a file path based on directory structure.
 * Uses word-boundary matching to avoid false positives (e.g., domain "auth"
 * should match "auth-service.ts" but not "authorize.ts").
 */
export function inferDomainFromPath(filePath: string, knownDomains: string[]): string | null {
  const normalizedPath = filePath.toLowerCase();
  const parts = normalizedPath.split('/');

  // Sort domains by length (longest first) so more specific names match first
  const sortedDomains = [...knownDomains].sort((a, b) => b.length - a.length);

  for (const domain of sortedDomains) {
    const normalizedDomain = domain.toLowerCase();

    // Direct directory match: src/auth/... → auth
    if (parts.some(p => p === normalizedDomain)) {
      return domain;
    }

    // Word-boundary prefix match on filename: "auth-handler" or "auth_service" → auth
    // Requires the domain name to be followed by a separator (-, _, .) or end of string.
    // This prevents "auth" from matching "authorize" or "authentication".
    const fileName = parts[parts.length - 1].replace(/\.[^.]+$/, '');
    if (fileName === normalizedDomain) {
      return domain;
    }
    // Check for word-boundary after domain name: auth-service, auth_handler, auth.utils
    const afterDomain = fileName.slice(normalizedDomain.length);
    if (fileName.startsWith(normalizedDomain) && afterDomain.length > 0 && /^[-_.]/.test(afterDomain)) {
      return domain;
    }
  }

  return null;
}

// ============================================================================
// SPEC MAP BUILDER
// ============================================================================

/**
 * Build a bidirectional map between spec domains and source files
 */
export async function buildSpecMap(options: SpecMapperOptions): Promise<SpecMap> {
  const { rootPath, openspecPath } = options;
  const specsDir = join(openspecPath, 'specs');
  const byDomain = new Map<string, SpecMapping>();
  const byFile = new Map<string, string[]>();

  // Read all spec domain directories
  let entries;
  try {
    entries = await readdir(specsDir, { withFileTypes: true });
  } catch {
    logger.debug('No specs directory found');
    return { byDomain, byFile, domainCount: 0, totalMappedFiles: 0 };
  }

  // Skip meta-directories that aren't domain specs (overview/architecture are
  // structural docs, not source-file-owning domains). Note: 'api' is NOT skipped
  // because many projects legitimately have an api domain with source files.
  const skipDomains = new Set(['overview', 'architecture']);

  for (const entry of entries) {
    if (!entry.isDirectory()) continue;

    const domain = String(entry.name);
    const specPath = join(specsDir, domain, 'spec.md');
    const relativeSpecPath = relative(rootPath, specPath);

    let content: string;
    try {
      content = await readFile(specPath, 'utf-8');
    } catch {
      logger.debug(`Could not read spec: ${specPath}`);
      continue;
    }

    // Parse the spec for source files
    const header = parseSpecHeader(content);
    const refs = parseSpecReferences(content);

    // Combine declared (header) and inferred (body) source files, deduplicated
    const declaredSourceFiles = header.sourceFiles;
    const inferredSourceFiles = refs.files.filter(f => !declaredSourceFiles.includes(f));
    const allSourceFiles = [...new Set([...declaredSourceFiles, ...inferredSourceFiles])];

    const mapping: SpecMapping = {
      domain,
      specPath: relativeSpecPath,
      declaredSourceFiles,
      inferredSourceFiles,
      allSourceFiles,
      requirements: refs.requirements,
      entities: refs.entities,
    };

    byDomain.set(domain, mapping);

    // Build reverse map (skip meta-domains for file mapping)
    if (!skipDomains.has(domain)) {
      for (const file of allSourceFiles) {
        const existing = byFile.get(file) ?? [];
        if (!existing.includes(domain)) {
          existing.push(domain);
          byFile.set(file, existing);
        }
      }
    }
  }

  // If repo-structure.json exists, enhance mapping with directory-based inference
  if (options.repoStructurePath) {
    try {
      const repoContent = await readFile(options.repoStructurePath, 'utf-8');
      const repoStructure = JSON.parse(repoContent);

      if (repoStructure.domains && Array.isArray(repoStructure.domains)) {
        for (const rsDomain of repoStructure.domains as RepoStructureDomain[]) {
          const domainName = rsDomain.name?.toLowerCase();
          if (!domainName || skipDomains.has(domainName)) continue;

          const mapping = byDomain.get(domainName);
          if (mapping && rsDomain.files) {
            for (const file of rsDomain.files) {
              if (!mapping.allSourceFiles.includes(file)) {
                mapping.inferredSourceFiles.push(file);
                mapping.allSourceFiles.push(file);
              }

              const existing = byFile.get(file) ?? [];
              if (!existing.includes(domainName)) {
                existing.push(domainName);
                byFile.set(file, existing);
              }
            }
          }
        }
      }
    } catch {
      logger.debug('Could not load repo-structure.json for enhanced mapping');
    }
  }

  // Count total unique mapped files
  const totalMappedFiles = byFile.size;

  return {
    byDomain,
    byFile,
    domainCount: byDomain.size,
    totalMappedFiles,
  };
}

/**
 * Load spec content for a domain, reading the spec file from disk.
 * Returns the markdown content truncated to maxChars, or null if unavailable.
 */
export async function getSpecContent(
  domain: string,
  specMap: SpecMap,
  rootPath: string,
  maxChars: number = 4000,
): Promise<string | null> {
  const mapping = specMap.byDomain.get(domain);
  if (!mapping) return null;

  try {
    const fullPath = join(rootPath, mapping.specPath);
    const content = await readFile(fullPath, 'utf-8');
    return content.length > maxChars
      ? content.slice(0, maxChars) + '\n... (truncated)'
      : content;
  } catch {
    logger.debug(`Could not read spec for domain: ${domain}`);
    return null;
  }
}

/**
 * Find which domains a file maps to, using direct lookup + directory inference
 */
export function matchFileToDomains(filePath: string, specMap: SpecMap): string[] {
  // Direct lookup
  const direct = specMap.byFile.get(filePath);
  if (direct && direct.length > 0) {
    return direct;
  }

  // Directory inference: try matching against known domain names
  const knownDomains = [...specMap.byDomain.keys()];
  const inferred = inferDomainFromPath(filePath, knownDomains);
  if (inferred) {
    return [inferred];
  }

  return [];
}

// ============================================================================
// ADR MAPPING
// ============================================================================

export interface ADRMapping {
  id: string;
  title: string;
  adrPath: string;
  relatedDomains: string[];
  relatedLayers: string[];
  status: string;
}

export interface ADRMap {
  byId: Map<string, ADRMapping>;
  byDomain: Map<string, string[]>;
}

/**
 * Parse the ## Related section from an ADR file to extract domains and layers.
 */
export function parseADRRelated(content: string): { domains: string[]; layers: string[] } {
  const domains: string[] = [];
  const layers: string[] = [];

  const domainsMatch = content.match(/\*\*Domains\*\*:\s*(.+)/);
  if (domainsMatch) {
    domains.push(...domainsMatch[1].split(',').map(d => d.trim()).filter(Boolean));
  }

  const layersMatch = content.match(/\*\*Layers\*\*:\s*(.+)/);
  if (layersMatch) {
    layers.push(...layersMatch[1].split(',').map(l => l.trim()).filter(Boolean));
  }

  return { domains, layers };
}

/**
 * Parse ADR title and status from content.
 */
function parseADRHeader(content: string): { id: string; title: string; status: string } {
  let id = '';
  let title = '';
  let status = 'accepted';

  // Parse title: # ADR-001: Some Title
  const titleMatch = content.match(/^#\s+(ADR-\d+):\s*(.+)/m);
  if (titleMatch) {
    id = titleMatch[1];
    title = titleMatch[2].trim();
  }

  // Parse status from ## Status section
  const statusMatch = content.match(/## Status\s+(\w+)/);
  if (statusMatch) {
    status = statusMatch[1].toLowerCase();
  }

  return { id, title, status };
}

/**
 * Build an ADR map by reading all ADR files from the decisions directory.
 * Returns null if no decisions directory exists.
 */
export async function buildADRMap(options: SpecMapperOptions): Promise<ADRMap | null> {
  const decisionsDir = join(options.openspecPath, 'decisions');
  const byId = new Map<string, ADRMapping>();
  const byDomain = new Map<string, string[]>();

  let entries: string[];
  try {
    entries = await readdir(decisionsDir);
  } catch {
    return null;
  }

  const adrFiles = entries.filter(f => f.startsWith('adr-') && f.endsWith('.md'));
  if (adrFiles.length === 0) return null;

  for (const fileName of adrFiles) {
    try {
      const filePath = join(decisionsDir, fileName);
      const content = await readFile(filePath, 'utf-8');
      const { id, title, status } = parseADRHeader(content);

      if (!id) continue;

      // Skip superseded/deprecated ADRs
      if (status === 'superseded' || status === 'deprecated') continue;

      const { domains, layers } = parseADRRelated(content);
      const adrPath = relative(options.rootPath, filePath);

      const mapping: ADRMapping = {
        id,
        title,
        adrPath,
        relatedDomains: domains,
        relatedLayers: layers,
        status,
      };

      byId.set(id, mapping);

      for (const domain of domains) {
        const existing = byDomain.get(domain) ?? [];
        existing.push(id);
        byDomain.set(domain, existing);
      }
    } catch {
      logger.debug(`Could not read ADR file: ${fileName}`);
    }
  }

  if (byId.size === 0) return null;

  return { byId, byDomain };
}
